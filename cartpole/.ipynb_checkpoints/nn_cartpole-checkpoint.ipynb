{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Base/')\n",
    "\n",
    "from imports import *\n",
    "from sequential_models import FCQ\n",
    "from training_startegy import EGreedyExpStrategy, GreedyStrategy\n",
    "from env import get_make_env_fn\n",
    "\n",
    "from Base import ReplayBuffer\n",
    "from dqn import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = (12,)\n",
    "\n",
    "environment_settings = {\n",
    "        'env_name' : 'CartPole-v1',\n",
    "        'gamma': 1.00,\n",
    "        'max_minutes': 20,\n",
    "        'max_episodes': 1,\n",
    "        'goal_mean_100_reward': 475\n",
    "    }\n",
    "\n",
    "model_hidden_layers = [512,128]\n",
    "\n",
    "#training strategy params\n",
    "init_epsilon = 1.0\n",
    "min_epsilon=0.3\n",
    "decay_steps=20000\n",
    "\n",
    "#replay buffer\n",
    "max_size=50000\n",
    "batch_size=64\n",
    "n_warmup_batches = 5\n",
    "update_target_every_steps = 10\n",
    "value_optimizer_lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dqn_results = []\n",
    "log.info(environment_settings)\n",
    "for seed in SEEDS:\n",
    "\n",
    "    #Neural Net\n",
    "    value_model_fn = lambda nS, nA: FCQ(nS, nA, hidden_dims = model_hidden_layers)\n",
    "\n",
    "    #Optimizer\n",
    "    value_optimizer_fn = lambda net, lr: optim.RMSprop(net.parameters(), lr=lr)\n",
    "\n",
    "    #Training Strategy\n",
    "    training_strategy_fn = lambda: EGreedyExpStrategy(init_epsilon=init_epsilon,  \n",
    "                                                      min_epsilon=min_epsilon, \n",
    "                                                      decay_steps=decay_steps)\n",
    "    #Testing Strategy\n",
    "    evaluation_strategy_fn = lambda: GreedyStrategy()\n",
    "\n",
    "    #Memory\n",
    "    replay_buffer_fn = lambda: ReplayBuffer(max_size=max_size, batch_size=batch_size)\n",
    "    \n",
    "    #Environment\n",
    "    env_name, gamma, max_minutes, \\\n",
    "    max_episodes, goal_mean_100_reward = environment_settings.values()\n",
    "\n",
    "    #Agent with all above functions\n",
    "    agent = DQN(replay_buffer_fn,\n",
    "                value_model_fn,\n",
    "                value_optimizer_fn,\n",
    "                value_optimizer_lr,\n",
    "                training_strategy_fn,\n",
    "                evaluation_strategy_fn,\n",
    "                n_warmup_batches,\n",
    "                update_target_every_steps)\n",
    "\n",
    "    make_env_fn, make_env_kargs = get_make_env_fn(env_name=env_name)\n",
    "\n",
    "    #Taining the agent!!!\n",
    "    result= agent.train(\n",
    "        make_env_fn, make_env_kargs, seed, gamma, max_minutes, max_episodes, goal_mean_100_reward)\n",
    "\n",
    "    dqn_results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.demo_progression()\n",
    "a = agent.demo_progression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# with open('qwe.html', 'w') as r: \n",
    "#     r.write(str(a))\n",
    "\n",
    "\n",
    "print(a.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bitb3bb7bd63e754d039c060b4d3666c0b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
